{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca18e2c9-e01c-4c9b-92c5-ced7b67aae77",
   "metadata": {},
   "source": [
    "# Árboles de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa42de93-9613-4be9-adeb-880903cd775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56481e94-5788-40f5-b687-a1cd60af5d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, 2:]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e83291-b3fb-4e03-bc98-4bfe1e7e5e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth = 2)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc004942-3ecb-4507-a10d-c3d0e0188e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "with open(\"img/tree.dot\", 'w') as f:\n",
    "    export_graphviz(\n",
    "        tree_clf,\n",
    "        out_file = f,\n",
    "        feature_names = iris.feature_names[2:],\n",
    "        class_names = iris.target_names,\n",
    "        rounded = True,\n",
    "        filled = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a5715-10bc-4f5f-b6f2-10d5c938f5fb",
   "metadata": {},
   "source": [
    "En consola: dot -Tpng img/tree.dot -o img/iris_tree.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06673b0-5ed4-4275-9378-a78c369475de",
   "metadata": {},
   "source": [
    "![alt text](img/iris_tree.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abaa97d-db44-4223-a40e-46bf74090e28",
   "metadata": {},
   "source": [
    "## Hacer predicciones\n",
    "\n",
    "Si conseguimos una flor iris y queremos clasificarla. Empezamos por el nodo raíz (profundidad 0): este nodo pregunta si el ancho del pétalo es inferior o igual a 0.8 cm. Si lo esm bajamos al nodo hijo de la izquierda (profundida 1). En este caso, se trata de un \"nodo terminal\" (es decir, no tiene nodos hijos), así que no formula ninguna pregunta: las clase predicha es Iris setosa.\n",
    "\n",
    "Ahora, si otra flor Iris nos indica que el ancho de su pétalo es mayor que 0.8 cm, se baja al nodo hijo de la derecha (profundidad 1), y dado que no es un nodo terminal, se realiza otra pregunta ¿el ancho del petalo es menor o igual a 1.75 cm? Si lo es, es probable que sea una Iris Versicolor (profundidad 2, izquierda), si no, seguramente será una Iris Virginica (profundidad 2, derecha)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521ac75-28b6-4d54-a0d3-02ff990f835c",
   "metadata": {},
   "source": [
    "Nota: Una de las múltiples cualidades de los árboles de decisión es que requieren muy poca preparación de los datos. No necesitas escalar las características ni centrarlas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9889ce0d-33a2-4fd5-a99c-39e50fa5f216",
   "metadata": {},
   "source": [
    "El atributo _sample_ de un nodo nos cuenta cuántas instancias del entrenamientos aplican para dicho nodo.\n",
    "\n",
    "El atributo _value_ indica a cuántas instancias de entrenamiento de cada clase aplican para dicho nodo.\n",
    "\n",
    "El atributo _gini_ es un nodo que mide la impureza de un nodo: un nodo es \"puro\" (gini = 0) si todas las isntancias de entrenamientoa las que aplican para dicho nodo pertenecen a la misma clase predicha por el nodo.\n",
    "\n",
    "$ G_i = 1 \\sum_{i=1}^{n} {p_{i,k}^2} $\n",
    "\n",
    "- $p_{i,k}$ es el ratio de instancias de clase $k$ entre las instancias de entrenamientos del nido $i$-esimo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac424957-5c24-4008-a3aa-a6a05bf1309a",
   "metadata": {},
   "source": [
    "### Interpretación del modelo: Caja Blanca vs Caja Negra\n",
    "\n",
    "Los árboles de decisión son intuitivos y sus decisiones son fáciles de interpretar. Tales modelos se denominan a menudos modelos de caja blanca. En cambio, como veremos, los _random forest_ o las redes neuronales se consideran generalmente modelos de caja negra. Hacen predicciones geniales y puedes comprobar con facilidad los cálculos que realizan para hacerlas: pero por lo general es difícil de explicar en términos sencillos por que se han hecho las predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96efb30-fc6f-443f-930c-7cb313845b50",
   "metadata": {},
   "source": [
    "## Estimación de probabilidad de clase\n",
    "\n",
    "Un árbol de decisión también puede estimar probabilidad de que una instancia pertenezca a una clase $k$ en particular. Primero recorre el árbol para encontrar el nodo terminal para esta instancia y luego devuelve el ratio de instancias de entrenamiento de clase $k$ en este nodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aa9849e-d3d6-48f8-b00b-c290f258c3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.90740741, 0.09259259]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict_proba([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5bc0055-8f62-412d-aa94-da87babaa7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe937727-7ceb-4171-8f93-feb527a57ae6",
   "metadata": {},
   "source": [
    "## Algoritmo de entrenamiento CART\n",
    "\n",
    "Sckit-Learn utiliza el algoritmo _Classification And Regression Tree_ (CART) para entrenar los árboles de decisión. Funciona dividiendo  primero el conjunto de entrenamiento en dos subconjuntos mediante una única característica $k$ y un umbral $t_k$ (por ejemplo, \"longitud del pétalo <= 2.45 cm\"). ¿Cómo elige $k$ y $t_k$? Se busca un par ($k$ y $t_k$) que produce los subconjuntos más puros (ponderados por tamaño). Siguiendo la función de perdida siguiente:\n",
    "\n",
    "$ J(k,t_k) = \\frac{m_{izq}}{m} G_{izq} + \\frac{m_{dcha}}{m} G_{dcha}$\n",
    "\n",
    "- G_{izq/dcha} mide la impureza del subconjunto izquierda/derecha.\n",
    "- m_{izq/dcha} es el número de instancias del subconjunto izquierda/derecha.\n",
    "\n",
    "Una vez que el algoritmo CART ha conseguido dividir el conjunto de entrenamiento en dos, divide los subconjuntos empleando la misma lógica, después los sub-conjuntos y así sucesivamente. Deja de repetir la operación cuando alcanza la profundidad máxima (definida por el hiperpárametro _max_depth_) o si no puede encontrar una división que reduzca la impureza.\n",
    "\n",
    "Otros hiperparámetros que controlan otras condiciones de detención son : _min_samples_split_, _min_samples_leaf_, _min_weight_fraction_leaf_, y _max_leaf_nodes_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d5e2c-0104-4bcf-9940-ef0284231470",
   "metadata": {},
   "source": [
    "Se sabe que encontrar el árbol óptimo es un problema NP-Completo: requiere un tiempo de $O(exp(m))$, lo que hace el problema intrincado incluso con conjuntos de entrenamiento pequeños."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78b953-10ec-40da-bb5d-83e2e8fa80d8",
   "metadata": {},
   "source": [
    "## Complejidad computacional\n",
    "\n",
    "Hacer predicciones requiere atravesar el árbol de decisión desde la raíz, hasta un nodo terminal. Los árboles de decisión suelen ser aproximadamente equilibrados, así que atravesar uno requiere recorrer exhaustivamente $O(log_2(m))$ nodos. Dado que cada nodo requiere comprobar el valor de una característic, la complejidad de predicción general es $O(log_2(m))$, independiente del número de características. Así pues, las predicciones son bastantes rápidas.\n",
    "\n",
    "El algoritmo de entrenamiento compara todas las características (o menos, si se configura _max_features_) en todas las muestras en cada nodo. El resultado de comprar todas las características de todas las muestras de entrenamiento de cada nodo es una complejidad de entrenamiento de $O(n * m * log_2(m))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62197ab-0f75-4f64-a2b0-57ba81c3f8f3",
   "metadata": {},
   "source": [
    "## ¿Impurezad e Gini o Entropía?\n",
    "\n",
    "Por defecto, se utiliza la medida de la impureza de Gini, pero se puede seleccionar la Entropía como medida de impireza configurando el hiperparámetro _criterion_ = \"entropy\".\n",
    "\n",
    "El concepto de entropía se origió en la termodinámica como medida de desorden molecular: la entroía se aproxima a cero cuando las moléculas están quietas y bien ordenadas. La entroía se extendió después a una amplia variedad de dominios, incluida la teoría de la información de Shannon, donde mide el contenido medio de información de un mensaje: la entropía es cero cuando todos los mensajes son idénticos. \n",
    "\n",
    "En _machine learning_, la entropía se utiliza con frecuencia como medida de impureza: la entropía de un conjunto es cero cuando contiene instancias de una sola clase.\n",
    "\n",
    "Ecuación de Entropía:\n",
    "\n",
    "$ H_i = \\sum_{k=1}^2{p_{i,k} log_2(p_{i,k})} $\n",
    "\n",
    "¿Cuál utilizar? Lo cierto es que, la mayoría de las veces, no hay mucha diferencia: conducen a árboles similares. \n",
    "- La impureza de Gini es ligeramente más rápida\n",
    "- La entropía tiende a producir árboles más equilibrados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b38071-0b1b-4159-a4f5-a2904d0fe2cb",
   "metadata": {},
   "source": [
    "P es el conjunto de problemas que pueden resolverse en tiempo polinomial. NP es el conjunto de problemas cuya solución se puede verificar en un tiempo polinomial. Un problema NP-difícil es un problema al cual puede reducirse cualquier problema NP en tiempo polinomial.\n",
    "\n",
    "La reducción de la entropía recibe a menudo el nombre de \"ganancia de información\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3548300-0069-4b7b-838b-643d6384abc4",
   "metadata": {},
   "source": [
    "## Hiperparámetros de regularización\n",
    "\n",
    "Los árboles de decisión asumen muy pocas cosas sobre los datos de entrenamiento (que por ejemplo los modelos lineales, que asumen que los datos son lineales). Si se deja sin restricciones, la estructura del árbol tomará la forma de las clases y amenudo sobreajustandolo.\n",
    "\n",
    "Este modelo se denomina a menudo \"modelo no paramétrico\", no por que no tenga parámetros, sino porque el número de parámetros no esta determinado antes del entrenamiento, así que la estructura del modelo es libre para ajustarse mucho a los parámetros predeterminados, así su grado de libertad está limitado. \n",
    "\n",
    "Para evitar el sobreajuste de los datos de entrenamiento, hay que restringir la libertad del árbol de decisión durante el entrenamiento, conocido como regularización. Los hiperparámetros de regularización dependen del algoritmo utilizado, pero por lo general podemos al menos restringir la profunidad máxima del árbol de decisión.\n",
    "\n",
    "Otros algoritmos funcionan entrenando primero el árbol de decisión sin restricciones y \"podando\" después los nodos innecesarios. Un nodo cuyo hijos son todos nodos terminales se considera innecesario si la mejora de la puireza que proporcionan no es estadísticamente significativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d5f4b-7a55-4f24-9cad-64316872241b",
   "metadata": {},
   "source": [
    "## Regresión\n",
    "\n",
    "Los árboles de decisión también son capaces de realizar tareas de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "764489e3-4593-4e9b-8cb5-e0bca263170c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc22849c-2ed0-4b2a-992d-1b4f7871a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"img/tree_reg.dot\", 'w') as f:\n",
    "    export_graphviz(\n",
    "        tree_reg,\n",
    "        out_file = f,\n",
    "        feature_names = iris.feature_names[2:],\n",
    "        class_names = iris.target_names,\n",
    "        rounded = True,\n",
    "        filled = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de4b274-96c0-4d3e-a907-93315ddbe5eb",
   "metadata": {},
   "source": [
    "dot -Tpng img/tree_reg.dot -o img/tree_reg.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad83da23-3bff-497d-8912-1897432d8181",
   "metadata": {},
   "source": [
    "![alt text](img/tree_reg.png \"Title1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
