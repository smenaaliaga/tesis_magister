{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8718c6f-b626-470e-ad04-39dea5d39076",
   "metadata": {},
   "source": [
    "# Ensamblaje y Random Forest\n",
    "\n",
    "Imagina que haces una pregunta compleja a miles de personas aleatorias y, después, ponderas sus respuestas. En muchos casos, te encontrarás con que esta respuesta ponderada es mejor que las respuestas de un experto. Esto se denomina sabiduría colectiva.\n",
    "\n",
    "De modo similar, si ponderas las predicciones mejoras que con el mejor predictor individual. Un grupo de predictores se denomina ensamble; así se conoce como técnica de ensamblaje.\n",
    "\n",
    "Como ejemplo de método de ensamblaje, puedes entrenar un grupo de árboles de decisión, cada uno en un subconjunto aleatorio del conjunto de entrenamiento aleatorio. Para hacer predicciones, obtienes los predictores de todos los árboles individuales y, después, predices la clase que consiga más votos. Un ensamble de árboles se denomina _Random Forest_, y pese a su simplicidad, es uno de los algoritmos de _machine learning_ más potentes en la actualidad.\n",
    "\n",
    "Los métodos de ensamblaje más populares son _bagging_, _boosting_ y _stacking_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f89f202-37a5-414d-a54f-13d21631b795",
   "metadata": {},
   "source": [
    "## Clasificadores de votación\n",
    "\n",
    "Supongamos que has entrenados varios clasificadores y cada uno ha consegudo una exactitud al rededor del 80%. Puede que tengas una Regresión Logística, un clasificador SVM, un _Random Forest_, un kNN y algunos más. Una manera muy sencilla de crear un clasificador aún más potente es sumar las predicciones de clasificadores y predecir la clase que obtiene más votos. Este clasificador por votos de la mayoría se llama clasificador _hard voting_.\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/W7UmY.png\" width=\"500\" />\n",
    "\n",
    "De estra manera, este clasificador consigue a menudo una exactitud mayor que el mejor clasificador del ensamble.\n",
    "\n",
    "Si tenemos una moneda ligeramente desequilibrada que tiene un 51% de posibilidades de caer cara. Si la lanzamos 1.000 veces, en general saldrían más o menos 510 caras y 490 cruces y, por lo tanto, una mayoría de caras. Si haces los cálculos, la posibilidad de tener mayoría de caras después de 1.000 lanzamientos se acerca al 75%, y cuando más se lance la moneda más alta es esta probabilidad (ej. con 10.000 lanzamientos, sube al 97%). Esto se debe a la Ley de los grandes número TLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3ae98d9-bcc5-4a54-a0e6-bcad2dfd786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_moons(n_samples=1000, noise=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301be854-0440-45d4-850c-8d28824b30a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0fd4218-14a4-493b-928f-df3984e72ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd7c2726-2f40-4f71-8ef6-f4b06e9a68f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier()), (&#x27;svc&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier()), (&#x27;svc&#x27;, SVC())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting = 'hard'\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6154ed-9e57-4768-8114-4b4cdd0caab3",
   "metadata": {},
   "source": [
    "Exactitud de cada clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed76001c-f00c-48ea-a314-14f6fffb41b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9\n",
      "RandomForestClassifier 0.9\n",
      "SVC 0.9333333333333333\n",
      "VotingClassifier 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf) :\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6698b125-4efd-4b53-b810-a180d6882d6d",
   "metadata": {},
   "source": [
    "Si todos los clasificadores son capaces de estimar las probabilidades de clase (es decir, todos tienen el método predict_proba()), se puede solicitar que prediga a través de la clase con más alta probabilidad, esto se denomina _soft voting_. A menudo consigue un rendimiento más alto que el _hard voting_ por que da más peso a los botos que son más seguros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "386eec17-74ca-40d2-a70c-3cf0154bb7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier())],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier())],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier())],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('lr', log_clf), ('rf', rnd_clf)],\n",
    "    voting = 'soft'\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "991d3a65-4412-4c91-88ea-06bd7afba3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9\n",
      "RandomForestClassifier 0.9333333333333333\n",
      "VotingClassifier 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "for clf in (log_clf, rnd_clf, voting_clf) :\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49850917-9a72-482e-8fdf-f5a5bc7f1605",
   "metadata": {},
   "source": [
    "## Bagging y Pasting\n",
    "\n",
    "Una forma de obtener un conjunto diverso de clasificadores es usar algoritmos de entrenamientos muy diferentes, como ya hemos visto. Otro enfoque es utilizar el mismo algoritmo para todos los predictores y entrenarlos en subconjuntos aleatorios distintos al conjunto de entrenamiento. Cuando se realiza un muestreo con reemplazo, este método se denomina __bagging__ (boostrap aggregation). Cuando el muestreo se realiza sin reemplazo se denomina __pasting__.\n",
    "\n",
    "Dicho de otro modo, tanto como _bagging_ como _pasting_ permiten entrenar instancias para que se muestreen varias veces a través de multiples predictores, pero solo el _bagging_ permite entrenar instancias para que se muestreen varias veces para el mismo predictor.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*iskng0M2Qv9GF0CADcl0Ww.png\" width=\"600\" />\n",
    "\n",
    "Una vez todos los predictores están entrenados, el ensamble puede hacer una predicción para una nueva instancia con solo agregar las predicciones de todos los predictores. La función de agregación suele ser el modo estadístico (el más frecuente además de _hard voting_) para clasificación o el promedio para la regresión. Cada predictor individual tiene un sesgo más alto que si se entrenase con el conjunto de datos indivudual, pero la agregación reduce el sesgo como la varianza.\n",
    "\n",
    "### Bagging y pasting en Sckit-Learn\n",
    "\n",
    "Se desarrolla un ensamblador de 500 clasificadores de arboles de decisión, Cada uno se entrena en 100 instancias de entrenamiento, aleatoriamente muestradas del conjunto de entrenamiento con reemplazo (_bagging_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40762c66-0b8f-4db3-b822-6dfb1c0a747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dcdac8-8844-42c1-96ed-8c948e0ebeba",
   "metadata": {},
   "source": [
    "Nota: El BaggingClassifier realiza _soft voting_ de forma automática, si el clasificador lo permite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9307d291-a9ea-4270-9e5e-b6786fa1759d",
   "metadata": {},
   "source": [
    "Tal como se observa en la imagen, un ensamble con _bagging_ de 500 arboles es capaz de generalizar mucho mejor que un solo arbol de decisión, tiene un mayor sesgo pero una menor varianza, osea, comete aproximadamente el mismo número de errores en el conjunto de entrenamiento, pero el límite de decisión es menos irregular.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1006/1*dCU5rsihNgN6rZrR3jpPwA.png\" width=\"500\" />\n",
    "\n",
    "El método _bagging_ acaba con un sesgo ligeramente más alto que el _pasting_; pero la diversidad extra también significa que los predictores acaban estando menos correlacionados, así la varianza del ensamble se reduce. En general, _bagging_ tiene resultadores mejores, por lo que suele preferirse.\n",
    "\n",
    "Sin embargo, con el tiempo y CPU suficiente, se puede utilizar validación cruzada para evaluar tanto _bagging_ como _pasting_ para seleccionar el que mejor funcione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d6d82-5ccd-4003-9740-35b50cbe5e9f",
   "metadata": {},
   "source": [
    "### Evaluación fuera de la bolsa\n",
    "\n",
    "Con _bagging_, algunas instancais pueden muestrarse varias veces para cualquier predictor dado, mientras que otros pueden no muestrarse en absoluto. Por defecto, un BaggingClassifier muestrea m instancias de entrenamiento con reemplazo (boostrap=True), donde em es el tamaño del conjunto de entrenamiento. Eso significa que solo al rededor del 63% de las instancias de entrenamiento se muestran para cada predictor. Las no muestreadas se conocen como \"fuera de la bolsa\" (out-of-bag, oob)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb2dd6-586f-46f3-a6ba-5dee0fedd76e",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "El _Random Forest_ es un ensamble de árboles de decisión, entrenado, por lo general, mediante el método _bagging_. Habitualmente con max_samples establecidos como el tamaño del conjunto de entrenamiento. La función DecisionTreeClassifier es más conveniente y esta más optimizado para árboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4e2e715-6187-4bc9-80c4-213b1f9f8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred_rd = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3336b315-26bf-4dc0-a691-424829ecef67",
   "metadata": {},
   "source": [
    "El algoritmo introduce una aleatoriedad extra cuando hace crecer los árboles; en vez de buscar la mejor característica cuando divide un nodo,  busca la mejor característica de un subconjunto de características. Teniendo un resultado con mas diversidad de arboles, lo que compensa un sesgo más alto por una varianza más baja."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
