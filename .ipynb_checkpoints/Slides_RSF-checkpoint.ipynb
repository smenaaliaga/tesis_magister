{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22a1af70-52f7-4e25-a8c7-7285c7c8094d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## De Árboles de Decisión a  \n",
    "## Bosques Aleatorios de Supervivencia (RSF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b39f489-dce6-424c-bd68-55b175e5cc8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Por Sebastián Mena Aliaga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6325685-afae-4ced-86b1-c708d396cb37",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Sumario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2520e921-1fb4-4c42-9af5-6be03034637b",
   "metadata": {},
   "source": [
    "- Arboles de Decisión\n",
    "- Bosques Aleatorios\n",
    "- Análisis de Supervivencia\n",
    "- Bosques Aleatorios de Supervivencia (RSF)\n",
    "- Bibliografía"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efbc330-c7cb-4467-ab2b-1a2dd8406abb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e0b94-8a78-4bd0-a6d4-ceaa33ee956a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Es un modelo de predicción basado en decisiones. Son intuitivos y sus decisiones son fáciles de interpretar (Modelo de caja blanca).\n",
    "\n",
    "Pueden ser utilizados para tareas de clasificación y regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e39d731-b1fd-4d55-8fe4-b6703dd06623",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<img src=\"img/iris_tree.png\" width=\"350\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0709242-fac4-446e-9839-0401842af19a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Impureza del nodo\n",
    "\n",
    "La impureza de un nodo nos aporta información acerca de la probabilidad de no obtener la clase predicha por un nodo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f84d6-4258-456d-b8f4-09e46858d588",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Índice de Gini\n",
    "\n",
    "$ G_i = 1 \\sum_{i=1}^{n} {p_{i,k}^2} $\n",
    "\n",
    "Un nodo $i$-esimo es puro si $G_i = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb89c87-4b56-45d9-92f0-7ad11ac267c1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Entropía\n",
    "\n",
    "$ H_i = \\sum_{k=1}^2{p_{i,k} log_2(p_{i,k})} $\n",
    "\n",
    "Un nodo $i$-esimo es puro si $H_i = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c900290-efb7-41c1-8ff9-038c63b0ee88",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "$p_{i,k}$ es el ratio de instancias de clase $k$ entre las instancias de entrenamientos del nido $i$-esimo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d168f72f-a85f-40d1-a586-93cef74a7e21",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Entrenamiento del modelo: Algoritmo CART\n",
    "\n",
    "Se comienza diviendo el conjunto de entrenamiento en dos subconjuntos, mediante una característica $k$ y un umbral $t_k$.\n",
    "\n",
    "Ej. característcia ($k$:) longitud del pétalo iris; umbral ($t_k$): $\\leq$ 2.45 cm.\n",
    "\n",
    "### ¿Cómo se elige $k$ y $t_k$? \n",
    "\n",
    "Se selecciona ($k$, $t_k$) que produzca los nodos más puros (ponderados por tamaño), siguiendo la función de perdida:\n",
    "\n",
    "$ J(k,t_k) = \\frac{m_{izq}}{m} G_{izq} + \\frac{m_{dcha}}{m} G_{dcha}$\n",
    "\n",
    "$G_{izq/dcha}$ mide la impureza del subconjunto (nodo) izquierdo/derecha.\n",
    "\n",
    "$m_{izq/dcha}$ cantidad de instancias del subconjunto izquierda/derecha.\n",
    "\n",
    "Una vez el algoritmo divide el conjunto en dos subconjuntos, divide dichos subconjuntos siguiendo la misma lógica, después los subconjuntos sy así sucesivamente.\n",
    "\n",
    "Este proceso se repite hasta reducir completamente la impureza de los nodos o alcanzando la profundida máxima permitida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c04b65-5dc2-4267-a8bc-64f3da796670",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Complejidad Computacional\n",
    "\n",
    "Encontrar un árbol óptimo pertenece a los problemas NP-Completo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52f569f-0276-48f7-8219-fa7b9998af22",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "Teoría de la complejidad: ¿Cómo crece el coste computacional (memoria y tiempo) en resolver un determinado problema en relación a lo que crece en tamaño de dicho problema?\n",
    "\n",
    "Medir de como aumenta el coste computacional de solucionar un problema respecto al tamaño del problema\n",
    "\n",
    "Podemos medir la complejidad de los problemas y sus respectivos algoritmos\n",
    "\n",
    "NP : Conjunto de problemas en los que podemos comprobar en un tiempo razonable (polinomial) si una respuesta al problema es correcta o no.\n",
    "\n",
    "P : Conjunto de problemas en los que podemos encontrar una respuesta al problema en un tiempo razonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df254ea3-3edf-4e68-aa19-a03cd0f60728",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Entrenar el modelo, resultado de comparar todas las características de todas las muestras de entrenamiento de cada nodo, requiere un tiempo $O(n \\cdot m \\cdot log_2(m))$.\n",
    "\n",
    "m: número de atributos; n: número de instancias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36071770-5a5a-40c8-be58-ad0d6b06d106",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Realizar una predicción, recorrer el árbols desde el nodo raíz hasta el nodo terminal, requiere un tiempo aproximado de $O(log_2(m))$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdebd62-10f6-4da9-b0de-29803e6b54dc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Supuestos e hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca84fbb8-f0d4-4a6c-990c-5c93302ae9fe",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Los árboles de decisión asumen muy pocos supuesos sobre la distribución de los datos, se denominan a menudo \"modelos no paramétricos\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4801e83-e0b4-4587-96f6-3eb9349e2bc8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Para evitar el sobreajuste del modelo, se pueden utilizar hipterparámetros de regularización, si bien depende del algoritmo de entrenamiento utilizado, por lo general al menos se puede restringir la profundidadi máxima del árbol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f38779f-8525-4761-8117-8cd923a32107",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Una implementación básica en Sckit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a98a54-f07e-4524-8aee-a3fd44be69d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(\n",
    "    max_depth=2 # Profundidad máxima del árbol\n",
    ")\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f22e6c1-509f-4529-abc0-4f8329c76ed3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Ensamblaje y Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdeaad8-51ed-4c0a-b66b-29304d898fdb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "La idea básica detrás de los ensambladores es contar con diferentes modelos predictivos entrenados a partir de subconjuntos de un mismo conjunto de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5415b91-2ff0-481d-985b-70845c69cbf6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Los métodos más populares de ensamblaje son _bagging_, _boosting_ y _stacking_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d93cf2-657a-4aa3-8b2e-58b03a4ece36",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://miro.medium.com/max/4800/1*WLfYK7UUFgJEbNGMAwcRaQ.png\" width=\"550\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77187525-84f5-49e0-8146-eeb128942b45",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Claificadores por votación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a23471-6997-4afa-80c3-167d6b4f0a52",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Consiste en entrenar varios modelos (Regresión Logística, SVM, Árboles, etc.) a partir de un mismo conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557dd217-b081-4dba-ae43-91dbd941d5ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Para una nueva instancia, cada modelo genera una predicción. La predicción final del ensamblador será la predicción más votada de cada uno de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80906305-3332-45e1-ae32-dbcefc01731b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://i.stack.imgur.com/W7UmY.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681ddb1e-8279-497d-a5cb-da1d7dcd276c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Generamos datos dummy\n",
    "X, y = make_moons(n_samples=1000, noise=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee5a2c-87ba-41b2-af4e-9ca2d508c29e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "# Se crean las instancias de los modelos\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ed3b8-c6d9-48b9-80f7-61cb604e96b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "# Se crea la instancia de un ensamblador por votación\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting = 'hard'\n",
    ")\n",
    "# Se ajusta el modelo \n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7822ca92-381d-42d9-b70a-b59f3035d3e8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Rendimiento de los modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d683f79-bc7b-48c5-ae26-1d15736a296d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.87\n",
      "RandomForestClassifier 0.9466666666666667\n",
      "SVC 0.9566666666666667\n",
      "VotingClassifier 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Rendimiento de cada uno de los modelos\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf) :\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fd0f02-a2e7-4448-9cf8-e7797100e01c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Bagging y Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9578f8-cfa6-4e4f-a365-39c4bca86301",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Este enfoque crea un ensamblador de varios predictores a partir de un mismo algoritmo, y los entrena en diferentes subconjuntos aleatorios de un mismo conjunto de entrenamiento por cada predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af51f87-b434-4d61-b784-e97a6509dc17",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "El método __bagging__ muestrea subconjuntos con remplazo y __pasting__ lo hace sin remplazo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd63be9e-3665-4f23-9633-979fe54b5e9e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://miro.medium.com/max/1400/1*iskng0M2Qv9GF0CADcl0Ww.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f6844-f7e4-460f-a4e0-db85ea8168e2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Tal como se observa en la imagen, un ensamble con _bagging_ de 500 árboles es capaz de generalizar mucho mejor que un solo árbol. Posee un mayor sesgo pero es compensado con una menor varianza.\n",
    "\n",
    "<img src=\"https://static.wixstatic.com/media/dcb8fd_0af0229fa2bb499d96a4efd2248c3c9c~mv2.png/v1/fill/w_1000,h_360,al_c,usm_0.66_1.00_0.01/dcb8fd_0af0229fa2bb499d96a4efd2248c3c9c~mv2.png\" width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3509d3ba-3ef0-4f92-815c-922c21b1c09f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d1db8-994f-43b2-8e2c-e2806de118c0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "El algoritmo fue originalmente propuesto por Tim Kam Ho en 1995, y se propuso una extensión muy popular por Breiman en 2001."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6862ab-6749-443e-91fe-e9a539f5348d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "El _Random Forest_ es un ensamble de árboles de decisión, entrenados, por lo general, mediante método _bagging_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f7eebc-0d85-4d91-923e-c755ec1525a3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Esta implementación se especializa de la implementación de _Bagging Classifier_, debido a que introduce una aleatoriedad extra cuando se hacen crecer los árboles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b891e-749e-46ac-8237-43d30a3239c2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "En vez de buscar la mejor característica cuando divide un nodo, busca la mejor característica de un subconjunto de características. Esto permite más diversidad de árboles, compensando un sesgo más alto por una varianza más baja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5132fbe3-2a67-4a28-90c2-b5da85ad4ee5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Implementación de Bagging Classifier en Sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf770f-ad40-4bb8-a209-1cc41cdfba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(splitter = 'random', max_leaf_nodes = 16),\n",
    "    n_estimators = 500, max_samples = 1.0, bootstrap = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c049f63-2004-4586-85f0-cb1b5fd828c6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Implementación de Random Forest  en Sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8452a1c-5649-49bf-abd2-5395510a6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(\n",
    "    n_estimators=500, max_leaf_nodes=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc5f94-659d-40db-9f80-db71e855e32a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Extremely Randomized Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c24e7a-f258-462e-b150-4412af4acabd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Al crear un árbol en _Random Forest_, en cada nodo solo se considera un subconjunto aleatorio de características ($k$) para la división. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c81c5-8032-443a-bbbf-6684039c4ab9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Es posible hacer que los árboles sean aún más aleatorios al utilizar umbrales ($t_k$) aleatorios para cada característica ($k$), en vez de buscar los mejores umbrales posibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b4f624-8d75-49cb-a299-89e53b5c88d2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "De esta forma se compensa aún más el sesgo con una varianza más baja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d236d32-1f80-426d-95e0-17738efeb539",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Importancia de la características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3720169b-d3ff-4905-a6b5-b4863949c8c1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Una cualidad importante de los _Random Forest_ es que hacen posible medir la importancia de las características a través de cuanto reducen la impureza."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc116b2-d33d-4281-bd6d-1aa854f96655",
   "metadata": {},
   "source": [
    "$ J(k,t_k) = \\frac{m_{izq}}{m} G_{izq} + \\frac{m_{dcha}}{m} G_{dcha}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51943858-4153-4bd4-9494-38b496f49778",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    " Se escalan los resultados de manera que la suma de todas las importancias de cada característica sea 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1423aaa7-b57b-477a-b09d-02b2b59aee41",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1feeb2-55e4-48d0-a755-f8fde6420051",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators= 500, n_jobs=-1)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d4b3ed-433e-4f75-bcf4-3c6f2d7e15a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.09101929129155692\n",
      "sepal width (cm) 0.022339654089200075\n",
      "petal length (cm) 0.4116565687809954\n",
      "petal width (cm) 0.4749844858382477\n"
     ]
    }
   ],
   "source": [
    "for name, score in zip(iris[\"feature_names\"], \n",
    "                       rnd_clf.feature_importances_) :\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd72cb3-18fb-400b-8081-e8febb5b80a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Análisis de Supervivencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bcb7bd-cccd-4693-b735-169eb0eefac0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "El análisis de supervivencia es un subcampo de la estadística, cuyo  objetivo es analizar y modelar datos de un sujeto en estudio, donde el resultado es el tiempo hasta que ocurre un evento de interés y su probabilidad asociada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8310ae-8c6a-4942-8a0c-ac63d9cd2af8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Tiempo de supervivencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07837f16-e7a2-4467-85ea-e9e0d3147bde",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Sea $T_i$ una variable aleatoria no negativa que denota el tiempo hasta la ocurrencia de un evento de interés para una instancia $i$-esima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68b2569-4d4c-4b3a-8f86-23f0613ec0f4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Para una instancia data $i$, representada por el vector $(X_i, y_i, \\delta_i)$, donde $ X_i \\in \\Re^{1 \\times P} $ es el vector de características. \n",
    "\n",
    "$P$: número características.\n",
    "\n",
    "$\\delta_i$: indicador binario de ocurrencia del evento ($\\delta_i = 0$, instancia con censura a la derecha). \n",
    "\n",
    "$y_i$: tiempo observado de la instancia. Si se observa el evento se denota $T_i$, si hay censura se denota $C_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fa194b-c845-4025-a3af-e3722a0d6d0b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "$$\n",
    "y_i =\n",
    "\\begin{cases}\n",
    "T_i & \\quad \\text{si $ \\delta_i = 1 $}\\\\ \n",
    "C_i & \\quad \\text{si $ \\delta_i = 0 $}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc4dc20-3ffd-46c8-b4bf-e8f296566dd2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Censura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320bc6e9-3bfa-4d5d-9496-243e387e05ff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Existen eventos \"censurados\", del cual no se sabe el tiempo de ocurrencia del evento. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91986c77-28cd-4abe-8fcf-5a74e70c57a8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Existen tres tipos de censuras:\n",
    "\n",
    "- __Censura a la derecha__, donde el evento no logra ocurrir hasta el tiempo de medición del dato; \n",
    "- __Censura a la izquierda__, donde el sujeto existe antes de la medición del dato; \n",
    "- __Intervalo censurado__, donde el evento sabemos que ocurre en un intervalo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0345682e-cb38-484f-abd2-caf2b6837950",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Métodos estadístico y Machine Learning se han adaptado para trabajar con data censurada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa42c8a-f0f4-499b-8d5d-0e92760fecad",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://bigdata.go.th/wp-content/uploads/2020/09/Screenshot-2020-10-06-093522.png\" width=\"650\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533cf62-fb79-46f2-87ef-826997ad6eae",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "[[fuente](https://opus1993.github.io/myTidyTuesday/Survival.html)] Survival Analysis, Jim Gruman."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c812cc5e-fb3c-4523-883e-ccfd2a518dd3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Función de supervivencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e010bb-409a-42c1-96f6-81fd03c23df9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "La función se utiliza para representar la probabilidad de que el tiempo hasta el evento de interés no sea anterior a un tiempo específico $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec8b72-65e0-4b58-a03f-1ca0ea39a95d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Siendo este uno de los principales objetivos en el análisis de supervivencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f952c408-c35b-459d-bf17-04c306a634cf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "$S(t) = Pr(T \\geq t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d3ba5e-00bd-4185-a281-cea54e08fb06",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/Survival_function_1.svg/1920px-Survival_function_1.svg.png\" width=\"650\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcd5804-65c4-4b32-b91c-2a033f522f66",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Metricas de desempeño"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305d3d24-ebd3-41c4-909f-f18a2751fd31",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Debido a la presencia de censura en los datos de supervivencia, las métricas de evaluación estándar para la regresión, como R2, no son adecuadas para medir el rendimiento en el análisis de supervivencia. Por ello se deben utilizar medidas especializadas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb37054a-68c5-4a0f-bf9f-8755f6c4b491",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- __Indice C__: Conocido como indice de concordancia, dicha metrica considera el riesgo relativo de que ocurra un evento para diferentes instancias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e48a4c-2816-442a-a310-ac2082d5cbb3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- __Metrica Brier__: Desarrollada para predecir inicialmente la inexactitud del pronóstico meteorologico. Su resultado se encuentra en un rango entre 0 y 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36623236-e9cb-47d2-b979-0b365a4478e3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Taxonomía"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba654d-8c68-4fba-b2e4-585cb7036945",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "En términos generales, los métodos de análisis de supervivencia se pueden clasificar en dos categorías principales: métodos estadísticos y métodos basados en Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa9065d-dd14-480e-a581-16d38f6936dd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Los métodos de Machine Learning generalmente se aplican a los problemas de alta dimensión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf867e-82da-4409-ba46-c451092a6b8b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Los métodos estadísticos permiten hacen inferencias a partir de los resultados y comparar diferencias entre grupos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9063c3-f2d3-4040-ab24-a601e8117de4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://humboldt-wi.github.io/blog/img/seminar/group2_SurvivalAnalysis/overall1.jpg\" width=\"650\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd741a-d782-4732-b499-8e72b83e193b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://humboldt-wi.github.io/blog/img/seminar/group2_SurvivalAnalysis/overall2.jpg\" width=\"650\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7abf070-773f-40e6-aad2-3b34b1510efb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Estimador Nelson-Aalen y Función de Supervivencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a42eda-8515-40d6-ab43-8ee79c44cc9a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Anteriormente, definimos la función de supervivencia $S(t) = Pr(T \\geq t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e822137a-5fef-40d1-a60d-eeb69ba083cb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "La relación entre la CHF $H(t)$ y la Función de Supervivencia $S(t)$ viene dada por: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1798455-cda7-4689-a094-279ca9df89d1",
   "metadata": {},
   "source": [
    "$S(t) = exp[-H(t)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d7e8f3-9efe-4d9e-9286-bdf81200f9ba",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Predicción temprana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fd1f7c-a49a-47d0-ba76-33200ac7e5c2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Un buen modelo de supervivencia debe tener la capacidad de pronosticar la ocurrencia del evento en el futuro utilizando solo información en su etapa inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de5ec3-4062-4cf7-ad74-043ab1b987fa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "El enfoque de una Predicción en Etapa Temprana es tener la capacidad de pronosticar ocurrencia de eventos nuevos basado en información temprana."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb21b3-02cc-4c4f-bf95-8617ebb0ba59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Random Survival Forest (RSF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35ff13a-83a0-4bd0-9fb7-b3f0fb06810d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "El algoritmo fue propuesto por Hemant Ishwaran et al., en 2008."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48418274-85c9-4f4b-abae-1c466ab73b38",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "La metodología de _Random Survival Forest_ (RSF) amplía el método de _Random Forest_ (RF) propuesto por Breiman (2001)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4225990c-7067-45e1-ace0-4ba76dbe416e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "RSF son arboles de decisión capaces de trabajar con datos censurados a la derecha, y obtiene su predicción a partir del total de muertes esperadas dado un tiempo $t$, derivada de la __Función de Riesgo Acumulativo__ (_cumulative hazard function_, CHF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b322bb-1514-425d-94e1-10dd2f0669cc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Algoritmo RSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a20b594-a72a-41b8-b367-312a3f18296a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "1. Se realizan N bootstraping de la data de entrenamiento.\n",
    "\n",
    "2. Se hace crecer un árbol por cada subconjunto (Mediante CART). Por cada nodo de cada árbol se selecciona aleatoriamente una característica $k$. El nodo se divide utilizando el umbral $k$ que máximice la diferencia de supervivencia entre nodos hijos.\n",
    "\n",
    "3. Cada árbol crece a tamaño completo con la restricción de que un nodo terminal no debe tener menos de una muerte.\n",
    "\n",
    "4. Se calcula un CHF para cada árbol y se promedio para obtener el ensamble CHF.\n",
    "\n",
    "5. Usando datos OOB, se calcule el error de predicción para el ensamble CHF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c835944-96b4-4eef-9eda-ed36ecac9b3c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Nodo Terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586cd66d-3df8-467d-8afe-4690a6cdcc5f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "El árbol de supervivencia alcanza un punto de saturación (nodo terminal) debido al criterio que cada nodo debe contener un mínimo de una \"muerte\" ($d_0 > 0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e6e99-1318-4bd7-aef9-fbb521c9aced",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Se denota $(T_{1,h}, \\delta_{1,h}), ...,(T_{i,h}, \\delta_{i,h})$, siendo $T$ tiempo de supervivencia, la variable binaria $\\delta$ como la censura a la derecha, para cada individuo $i$ y nodo terminal $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7847342-6aa2-406f-95bd-6a1a0e559e18",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Se define $d_{l,h}$ e $Y_{l,h}$ como el número de muertes e individuos en riesgo en el momento $t_{l,h}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b276c-24c5-4a3c-9969-9872e9f8f958",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "La estimación de CHF para $h$ es el estimador de Nelson-Aalen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb92717-336c-4f2f-86d0-d49cacf9e1af",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{H}_h(t) =\n",
    "\\sum_{t_{l,h} \\leq t} \\frac{d_{l,h}}{Y_{l,h}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba63cb92-6f53-47f2-a38b-2f9c1983d713",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Todos los individuos $i$ dentro del nodo terminal $h$ tienen el mismo CHF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d33d01-6f6c-4b41-b546-fc1649e92153",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Cada individuo $i$ tiene una covariable $d$-dimensional denotada $X_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a73741-c85b-49ab-914a-978d0fae2c10",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Se define $H(t|X_i)$ como CHF del individuo $i$-esimo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cef9a9b-18ec-4bfc-9a3f-076d4b53a0ca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Dada la naturaleza binaria de un árbol de supervivencia, un individuo $i$ con características $X_i$ caerá a un único nodo terminal $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b14738f-1e3b-4aae-a17b-24ba3bf35f1a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "El CHF para $i$ es el estimador Nelson-Aalen para $X_i$ del nodo terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d797fb24-9ab7-481e-97cb-30f183752abc",
   "metadata": {},
   "source": [
    "$H(t|X_i) = \\hat{H}_h(t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1000564-c245-4256-9cc3-a938dfded5d1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "El CHF anteriormente descrito es para un árbol, para obtener el CHF del ensamble se deben promediar los CHF de todos los árboles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f80ad-d61e-429f-9a47-bc1f98b14137",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Bibliografía"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8427a7-49c5-47ec-9d37-0467d6dce488",
   "metadata": {},
   "source": [
    "Ishwaran, H., Kogalur, U. B., Blackstone, E. H., &#38; Lauer, M. S. (2008). Random Survival Forests. , 2(3), 841–860. \n",
    "\n",
    "Ra, Karthikeyan. (2015). A Comparison study of Kaplan-Meier and Nelson-Aalen Methods in Survival Analysis. 2. 34-38.\n",
    "\n",
    "Wang, P., Li, Y., Reddy, C. K. (2019). Machine Learning for Survival Analysis. _ACM Computing Surveys (CSUR)_, 51.\n",
    "\n",
    "Aurélien Géron. (2019). Hands-on machine learning with Scikit-Learn, Keras and TensorFlow: concepts, tools, and techniques to build intelligent systems. _O’Reilly Media_, 851."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "rise": {
   "theme": "sky"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
